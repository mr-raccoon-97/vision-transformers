{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from torch import flatten, randn, cat\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import GELU\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import LayerNorm\n",
    "from torch.nn import MultiheadAttention\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "\n",
    "class ImageEmbeddings(Module):\n",
    "    def __init__(self, image_width: int, image_height: int, input_channels: int, patch_size: int, model_dimension: int):\n",
    "        super().__init__()\n",
    "        self.number_of_patches = (image_width *  image_height // patch_size) ** 2        \n",
    "        self.projector = Conv2d(input_channels, model_dimension, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        output = self.projector(input)\n",
    "        return flatten(output, 2).transpose(1, 2)\n",
    "\n",
    "\n",
    "class CLSToken(Module):\n",
    "    def __init__(self, model_dimension: int):\n",
    "        super().__init__()\n",
    "        self.token = Parameter(randn(1, 1, model_dimension))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        batch_size = input.shape[0]\n",
    "        token = self.token.expand(batch_size, -1, -1)\n",
    "        return cat([token, input], dim=1)\n",
    "\n",
    "\n",
    "class LearnablePositionalEncoding(Module):\n",
    "    def __init__(self, model_dimension: int, number_of_patches: int):\n",
    "        super().__init__()\n",
    "        self.position_embeddings = Parameter(randn(1, number_of_patches + 1, model_dimension))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        input = input + self.position_embeddings\n",
    "        return input\n",
    "    \n",
    "\n",
    "class Encoder(Module):\n",
    "    def __init__(self, model_dimension: int, hidden_dimension: int, number_of_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.attention = MultiheadAttention(model_dimension, number_of_heads, dropout=dropout)\n",
    "        self.first_layer_normalization = LayerNorm(model_dimension)\n",
    "        self.second_layer_normalization = LayerNorm(model_dimension)\n",
    "        self.mlp = Sequential(\n",
    "            Linear(model_dimension, hidden_dimension),\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(hidden_dimension, model_dimension),\n",
    "            Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor, need_weights: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        output = self.first_layer_normalization(input)\n",
    "        attention, attention_weights = self.attention(output, output, output, need_weights=need_weights)\n",
    "        output = output + attention\n",
    "        output = self.second_layer_normalization(output)\n",
    "        output = output + self.mlp(output)\n",
    "        return output, attention_weights\n",
    "    \n",
    "@dataclass\n",
    "class Settings:\n",
    "    image_width: int\n",
    "    image_height: int\n",
    "    patch_size: int\n",
    "    input_channels: int\n",
    "    model_dimension: int\n",
    "    hidden_dimension: int\n",
    "    number_of_heads: int\n",
    "    number_of_layers: int\n",
    "    dropout: float\n",
    "\n",
    "class ViTClassifier(Module):\n",
    "    def __init__(self, settings: Settings, output_classes: int):\n",
    "        super().__init__()\n",
    "        self.image_embeddings = ImageEmbeddings(settings.image_width, settings.image_height, settings.input_channels, settings.patch_size, settings.model_dimension)\n",
    "        self.cls_token = CLSToken(settings.model_dimension)\n",
    "        self.positional_encoding = LearnablePositionalEncoding(settings.model_dimension, self.image_embeddings.number_of_patches)\n",
    "        self.encoders = ModuleList([Encoder(settings.model_dimension, settings.hidden_dimension, settings.number_of_heads, settings.dropout) for layer in range(settings.number_of_layers)])\n",
    "        self.classification_head = Linear(settings.model_dimension, output_classes)\n",
    "\n",
    "    def forward(self, input: Tensor, need_weights: bool = False) -> Tuple[Tensor, Optional[List[Tensor]]]:\n",
    "        output = self.image_embeddings(input)\n",
    "        output = self.cls_token(output)\n",
    "        output = self.positional_encoding(output)\n",
    "        attention_weights = []\n",
    "        for encoder in self.encoders:\n",
    "            output, weight = encoder(output, need_weights=need_weights)\n",
    "            if need_weights:\n",
    "                attention_weights.append(weight)\n",
    "\n",
    "        logits = self.classification_head(output[:, 0])\n",
    "        return logits, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.pyplot import figure, show, savefig\n",
    "from matplotlib.axes import Axes\n",
    "from uuid import UUID, uuid4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Protocol, Optional, Dict\n",
    "from csv import DictWriter\n",
    "from torch.optim import Optimizer\n",
    "from utils import train, test, Criterion, Data\n",
    "\n",
    "\n",
    "class Writer(Protocol):\n",
    "    def add_scalar(self, tag: str, scalar_value: float, global_step: int):\n",
    "        ...\n",
    "    \n",
    "class Metrics:\n",
    "    def __init__(self, writer: Optional[Writer] = None):\n",
    "        self.writer = writer\n",
    "        self.history = {\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "        }\n",
    "        self.epoch = 0\n",
    "\n",
    "    def start(self, mode: str):\n",
    "        self.mode = mode\n",
    "        self.epoch += 1\n",
    "        self.batch = 0\n",
    "        self.loss = 0\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def update(self, batch: int, loss: float, accuracy: float):\n",
    "        self.batch = batch\n",
    "        self.loss += loss\n",
    "        self.accuracy += accuracy\n",
    "    \n",
    "    def stop(self):\n",
    "        self.loss /= self.batch\n",
    "        self.accuracy /= self.batch\n",
    "        self.history['loss'].append(self.loss)\n",
    "        self.history['accuracy'].append(self.accuracy)\n",
    "        print(f'Processed {self.batch} batches, average loss: {self.loss:.4f}, average accuracy: {self.accuracy:.4f}, in epoch {self.epoch} for {self.mode} mode')\n",
    "\n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(f'{self.mode}/loss', self.loss, self.epoch)\n",
    "            self.writer.add_scalar(f'{self.mode}/accuracy', self.accuracy, self.epoch)\n",
    "\n",
    "    def write_to_csv(self, filename: str):\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['epoch', 'loss', 'accuracy']\n",
    "            writer = DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for epoch, (loss, accuracy) in enumerate(zip(self.history['loss'], self.history['accuracy']), start=1):\n",
    "                writer.writerow({'epoch': epoch, 'loss': loss, 'accuracy': accuracy})\n",
    "\n",
    "\n",
    "class Summary:\n",
    "    def __init__(self, name: str = None, id: UUID = None) -> None:\n",
    "        self.id = id or uuid4()\n",
    "        self.name = name or 'model'\n",
    "        self.metrics = {\n",
    "            'train': Metrics(),\n",
    "            'test': Metrics()\n",
    "        }\n",
    "\n",
    "    def open(self):\n",
    "        self.writer = SummaryWriter(log_dir=f'logs/{self.name}-{self.id}')\n",
    "        self.metrics['train'].writer = self.writer\n",
    "        self.metrics['test'].writer = self.writer\n",
    "        print(f\"Running experiment {self.name} with id {self.id}\")\n",
    "        print(f\"Tensorboard logs are saved in logs/{self.name}-{self.id}\")\n",
    "        print(f\"Run tensorboard with: tensorboard --logdir=logs/\")\n",
    "        print(f\"Open browser and go to: http://localhost:6006/\")\n",
    "        print(f\"----------------------------------------------------------------\")\n",
    "\n",
    "    def close(self):\n",
    "        print(f\"Experiment {self.name} with id {self.id} completed\")\n",
    "        print(f\"#### Results for {self.name}:\")\n",
    "        print(f\"- Average loss: {self.metrics['train'].loss:.4f} (train), {self.metrics['test'].loss:.4f} (test)\")\n",
    "        print(f\"- Average accuracy: {self.metrics['train'].accuracy:.4f} (train), {self.metrics['test'].accuracy:.4f} (test)\")\n",
    "        print(f\"----------------------------------------------------------------\")\n",
    "        \n",
    "        path = f\"{'results/'}{self.name}-{self.id}.csv\"\n",
    "        self.metrics['train'].write_to_csv(path.replace('.csv', '-train.csv'))\n",
    "        self.metrics['test'].write_to_csv(path.replace('.csv', '-test.csv'))\n",
    "        \n",
    "        self.writer.close()\n",
    " \n",
    "    def add_text(self, tag: str, text: str):\n",
    "        with open(f'parameters/{self.name}-{self.id}.txt', 'a') as f:\n",
    "            f.write(f'{tag}: {text}\\n')     \n",
    "\n",
    "        if self.writer:\n",
    "            self.writer.add_text(tag, text)\n",
    "\n",
    "        print(f'{tag}: {text}')\n",
    "        print(f\"----------------------------------------------------------------\")\n",
    "\n",
    "def plot(metrics: Dict[str, Metrics], metric: str, ax: Optional[Axes] = None):\n",
    "    if ax is None:\n",
    "        plot = figure()\n",
    "        ax = plot.add_subplot()\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        ax.plot(value.history[metric], label=key)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "    if ax is None:\n",
    "        show()\n",
    "\n",
    "\n",
    "def run(model: Module, optimizer: Optimizer, criterion: Criterion, device: str, data: Dict[str, Data], summary: Summary, epochs: int = 30):\n",
    "    summary.open()\n",
    "    summary.add_text('model', str(model))\n",
    "    summary.add_text('optimizer', str(optimizer))\n",
    "    summary.add_text('criterion', str(criterion))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, criterion, optimizer, data['train'], summary.metrics['train'], device)\n",
    "        test(model, criterion, data['test'], summary.metrics['test'], device)\n",
    "\n",
    "    summary.close()\n",
    "\n",
    "    metrics_plot = figure(figsize=(10, 5))\n",
    "    metrics_plot.suptitle(f'{summary.name}')\n",
    "    ax = metrics_plot.add_subplot(1, 2, 1)\n",
    "    plot(summary.metrics, 'loss', ax)\n",
    "\n",
    "    ax = metrics_plot.add_subplot(1, 2, 2)\n",
    "    plot(summary.metrics, 'accuracy', ax)\n",
    "\n",
    "    if not os.path.exists('./plots'):\n",
    "        os.makedirs('./plots')\n",
    "\n",
    "    savefig(f'plots/{summary.name}-{summary.id}.png', bbox_inches =\"tight\" )\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
